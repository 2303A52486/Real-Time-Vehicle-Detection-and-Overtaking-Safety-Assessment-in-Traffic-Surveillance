# -*- coding: utf-8 -*-
"""yolov8_pipeline

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11IvaIWrUeVRc1iCL8ls_HoAj4jytq4CS

## Phase 1: Environment Setup & Installation
"""

!pip install ultralytics opencv-python numpy torch torchvision

import os
import cv2
import numpy as np
import torch
import logging
from ultralytics import YOLO
from google.colab import files
from collections import deque

# Enable logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# Camera Calibration Parameters (Modify for Accuracy)
CAMERA_CONFIG = {
    "focal_length": 1200,
    "sensor_width": 6.17,
    "frame_width": 640,
    "frame_height": 384,
    "car_width": 1.8,
    "truck_width": 2.5,
    "bus_width": 2.6
}

"""## Phase 2: Load YOLOv8 Model"""

# Load YOLO Model
device = "cuda" if torch.cuda.is_available() else "cpu"
logging.info(f"Using device: {device}")
model = YOLO("yolov8m.pt").to(device)

# COCO Dataset Classes for Vehicles
VEHICLE_CLASSES = [2, 3, 5, 7]  # car, motorcycle, bus, truck
VEHICLE_COLORS = {
    "car": (0, 255, 0),       # Green
    "truck": (255, 0, 0),     # Blue
    "bus": (0, 0, 255),       # Red
    "motorcycle": (255, 255, 0),  # Cyan
    "default": (0, 255, 255)  # Yellow
}

"""## Phase 3: Core Utilities"""

# Distance Calculation Function
def calculate_distance(bbox, label):
    width_map = {
        "car": CAMERA_CONFIG["car_width"],
        "truck": CAMERA_CONFIG["truck_width"],
        "bus": CAMERA_CONFIG["bus_width"],
        "motorcycle": 0.8
    }
    real_width = width_map.get(label.lower(), 1.8)
    pixel_width = bbox[2] - bbox[0]
    return round((real_width * CAMERA_CONFIG["focal_length"]) / pixel_width, 2)

# Overtaking Angle Calculation
def calculate_overtaking_angle(bbox):
    obj_center = (bbox[0] + bbox[2]) / 2
    frame_center = CAMERA_CONFIG["frame_width"] / 2
    mm_per_pixel = CAMERA_CONFIG["sensor_width"] / CAMERA_CONFIG["frame_width"]
    offset_mm = (obj_center - frame_center) * mm_per_pixel
    return round(np.degrees(np.arctan(offset_mm / CAMERA_CONFIG["focal_length"])), 2)

# Angle Accuracy Calculation
def compute_angle_accuracy(predicted_angle, true_angle=0):
    error = abs(predicted_angle - true_angle)
    accuracy = max(0, 100 - (error / 90) * 100)
    return round(accuracy, 2)

"""## Phase 4: Process Video and Perform Object Detection

"""

# Process Video with Batch Processing
def process_video(input_path, output_path="output_video.mp4", batch_size=8):
    cap = cv2.VideoCapture(input_path)
    if not cap.isOpened():
        logging.error(f"Error opening video: {input_path}")
        raise FileNotFoundError(f"Error opening video: {input_path}")

    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

    frame_count = 0
    frame_queue = deque()  # Queue to store batch of frames
    logging.info("Processing started...")
    print(" Processing started...")

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame = cv2.resize(frame, (frame_width, frame_height), interpolation=cv2.INTER_AREA)
        frame_queue.append(frame)

        # Process batch when batch size is reached
        if len(frame_queue) == batch_size:
            process_batch(list(frame_queue), out)
            frame_queue.clear()  # Empty queue after processing

        frame_count += 1
        if frame_count % 50 == 0:
            logging.info(f"Processed {frame_count} frames...")
            print(f"Processed {frame_count} frames...")

    # Process remaining frames if any
    if frame_queue:
        process_batch(list(frame_queue), out)

    cap.release()
    out.release()
    print(f"✅ Completed! Processed {frame_count} frames, saved to {output_path}")

    # Automatically download the output in Colab
    logging.info("Downloading processed video...")
    print("Downloading processed video...")
    files.download(output_path)

# Batch Processing Function
def process_batch(frames, out):
    """Process a batch of frames with YOLOv8"""
    results = model(frames, verbose=False)

    for frame, result in zip(frames, results):
        for box in result.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
            conf = box.conf.item()
            cls_id = int(box.cls)
            label = model.names[cls_id].lower()

            if conf < 0.5:
                continue

            color = VEHICLE_COLORS.get(label, VEHICLE_COLORS["default"])
            distance = calculate_distance((x1, y1, x2, y2), label)
            angle = calculate_overtaking_angle((x1, y1, x2, y2))
            angle_accuracy = compute_angle_accuracy(angle)

            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            label_text = f"{label}, D:{distance:.2f}m, A: {angle:.2f}° | Acc: {angle_accuracy:.2f}%"
            cv2.putText(frame, label_text, (x1, max(y1 - 10, 20)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

        out.write(frame)

# Set Input and Output Paths for Colab
input_video = "/content/sample video2.mp4"
output_video = "output_video.mp4"

# Run Video Processing with Batch Inference
process_video(input_video, output_video, batch_size=8)